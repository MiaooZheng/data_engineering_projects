# Edition 1 sample chapters

This page contains drafts of several chapters from the first edition of our book, along with various other sections.


### TABLE OF CONTENTS


### PREFACE


### CHAPTER 1. Introduction 

How does machine learning work, and what can currently we do with it?  Here we discuss the basic building blocks of machine learning and show how they all fit together to solve real problems.


### CHAPTER 2. Fundamentals of numerical optimization

Topics include calculus defined optimality, as well as gradient descent and Newtonâ€™s method algorithms. Discussing these essential tools first will enable us to immediately and effectively deal with all of the formal learning problems we will see throughout the entirety of the text.


### CHAPTER 3. Knowledge-driven regression 

In this Chapter we describe the regression problem, as well as the notion of feature design for regression, in particular focusing on rare low dimensional instances, and end by describing the L2 regularizer and its use with nonconvex learning problems.

### CHAPTER 4. Knowledge-driven classification

Here the fundamental model for two-class classification, the perceptron, is introduced along with two equally effective relatives: logistic regression and support vector machines.  Muticlass classification is then detailed, as well as feature design for classification with a focus on commonly used histogram-based features.


### CHAPTER 9. Dimension reduction techniques

Here we describe general techniques for significantly reducing the size of datasets prior to performing regression or classification.  This includes data subsampling, K-means clustering, and Principal Component Analysis.  Recommender systems are also detailed as a variant of these methods.

### APPENDICES. Matrix algebra and calculus review 

In these appendices we review fundamental vector and matrix operations, as well as elements of calculus including taking scalar and vector derivatives.

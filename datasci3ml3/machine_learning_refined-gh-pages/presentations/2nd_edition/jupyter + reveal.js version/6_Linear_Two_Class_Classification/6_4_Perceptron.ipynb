{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6.4  The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- As we have seen with logistic regression we treat classification as a particular form of nonlinear regression (employing - with the choice of label values $y_p \\in \\left\\{-1,+1\\right\\}$ - a tanh nonlinearity). \n",
    "\n",
    "\n",
    "- This results in the learning of a proper nonlinear regressor, and a corresponding *linear decision boundary* \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathring{\\mathbf{x}}_{\\,}^{T}\\mathbf{w}^{\\,}=0.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Instead of learning this decision boundary as a result of a nonlinear regression, the *perceptron* derivation described in this Section aims at determining this ideal lineary decision boundary directly.  \n",
    "\n",
    "\n",
    "- While we will see how this direct approach leads back to the *Softmax cost function*.\n",
    "\n",
    "\n",
    "- Practically speaking the perceptron and logistic regression *often results in learning the same linear decision boundary*, the perceptron's focus on learning the decision boundary directly provides a valuable new perspective on the process of two-class classification.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- You can toggle the code on and off in this presentation via the button below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "# import custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "datapath = '../../mlrefined_datasets/superlearn_datasets/'\n",
    "\n",
    "# demos for this notebook\n",
    "regress_plotter = superlearn.lin_regression_demos\n",
    "optimizers = optlib.optimizers\n",
    "static_plotter = superlearn.classification_static_plotter.Visualizer();\n",
    "\n",
    "# import autograd functionality to bulid function's properly for optimizers\n",
    "import autograd.numpy as np\n",
    "\n",
    "# import timer\n",
    "from datetime import datetime \n",
    "\n",
    "# This is needed to compensate for %matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Perceptron cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- With two-class classification we have a training set of $P$ points $\\left\\{ \\left(\\mathbf{x}_{p},y_{p}\\right)\\right\\} _{p=1}^{P}$ - where $y_p$'s take on just two label values from $\\{-1, +1\\}$ - consisting of two classes which we would like to learn how to distinguish between automatically.  \n",
    "\n",
    "\n",
    "- As we saw in our discussion of logistic regression, in the simplest instance our two classes of data are largely separated by a *linear decision boundary* with each class (largely) lying on either side.  \n",
    "\n",
    "\n",
    "- This decision boundary, written as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathring{\\mathbf{x}}^{T}\\mathbf{w}^{\\,} = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- This boundary is a *point* when the dimension of the input is $N=1$, a *line* when $N = 2$, and is more generally for arbitray $N$ a *hyperplane* defined in the input space of a dataset.  \n",
    "\n",
    "\n",
    "- This scenario can be best visualized in the case $N=2$, where we view the problem of classification 'from above' - showing the input of a dataset colored to denote class membership.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  <img src= '../../mlrefined_images/superlearn_images/Fig_4_1.png' width=\"80%\" height=\"80%\" alt=\"\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The default coloring scheme we use here - matching the scheme used in the previous Section - is to color points with label $y_p = -1$ blue and $y_p = +1$ red.  \n",
    "\n",
    "\n",
    "- The linear decision boundary is here a line that best separates points from the $y_p = -1$ class from those of the $y_p = +1$ class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- A linear decision boundary cuts the input space into two *half-spaces*, one lying 'above' the hyperplane where $\\mathring{\\mathbf{x}}^{T}\\mathbf{w}^{\\,} > 0$ and one lying 'below' it where $\\mathring{\\mathbf{x}}^{T}\\mathbf{w}^{\\,}  < 0$.  \n",
    "\n",
    "\n",
    "- Notice then that a proper set of weights $\\mathbf{w}$ define a linear decision boundary that separates a two-class dataset as well as possible with *as many members of one class as possible lying above it, and likewise as many members as possible of the other class lying below it*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- So our *desired* set of weights define a hyperplane where as often as possible we have that\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}\n",
    "\\\n",
    "\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,} >0 & \\,\\,\\,\\,\\text{if} \\,\\,\\, y_{p}=+1\\\\\n",
    "\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,} <0 & \\,\\,\\,\\,\\text{if} \\,\\,\\, y_{p}=-1.\n",
    "\\end{array}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Because of our choice of label values we can consolidate the ideal conditions above into the single equation below\n",
    "\n",
    "\\begin{equation}\n",
    "-\\overset{\\,}{y}_{p}\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,} <0.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- Again we can do so specifically because we chose the label values $y_p \\in \\{-1,+1\\}$.  \n",
    "\n",
    "\n",
    "- Likewise by taking the maximum of this quantity and zero we can then write this ideal condition as\n",
    "\n",
    "\\begin{equation}\n",
    "g_p\\left(\\mathbf{w}\\right) = \\text{max}\\left(0,\\,-\\overset{\\,}{y}_{p}\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,}\\right)=0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Note that the expression $\\text{max}\\left(0,-\\overset{\\,}{y}_{p}\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,}\\right)$ is always nonnegative.\n",
    "\n",
    "\n",
    "- The functional form of this point-wise cost $\\text{max}\\left(0,\\cdot\\right)$ is called a *rectified linear unit*.  \n",
    "\n",
    "\n",
    "- Because these point-wise costs are nonnegative and equal *zero* when our weights are tuned correctly, we can take their average over the entire dataset to form a proper cost function as\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "g\\left(\\mathbf{w}\\right)=  \\frac{1}{P}\\sum_{p=1}^Pg_p\\left(\\mathbf{w}\\right) = \\frac{1}{P}\\sum_{p=1}^P\\text{max}\\left(0,-\\overset{\\,}{y}_{p}\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,}\\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- When minimized appropriately this cost function can be used to recover the ideal weights.\n",
    "\n",
    "\n",
    "- This cost function goes by many names such as the *perceptron* cost, the *rectified linear unit* cost (or *ReLU cost* for short), and the *hinge cost*.\n",
    "\n",
    "\n",
    "- This cost function is *always convex* but has only a single (discontinuous) derivative in each input dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- This implies that we can only use zero and first order local optimization schemes (i.e., not Newton's method).  \n",
    "\n",
    "\n",
    "- Note that the perceptron cost *always* has a trivial solution at  $\\mathbf{w} = \\mathbf{0}$, since indeed $g\\left(\\mathbf{0}\\right) = 0$, thus one may need to take care in practice to avoid finding it (or a point too close to it) accidentally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The smooth softmax approximation to the ReLU cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Learning and optimization go hand in hand, and as we know from the discussion above the ReLU function limits the number of optimization tools we can bring to bear for learning. \n",
    "\n",
    "\n",
    "- Here we describe a common approach to ameliorating this issue by introducing a smooth approximation to this cost function. \n",
    "\n",
    "\n",
    "- If the approximation closely matches the true cost function then for the small amount of accuracy (we will after all be minimizing the approximation, not the true function itself) we significantly broaden the set of optimization tools we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- One popular way of doing this for the ReLU cost function is via the *softmax* function defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{soft}\\left(s_0,s_1,...,s_{C-1}\\right) = \\text{log}\\left(e^{s_0} + e^{s_1} + \\cdots + e^{s_{C-1}} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- Here $s_0,\\,s_1,\\,...,s_{C-1}$ are any $C$ scalar vaules - which is a generic smooth approximation to the *max* function, i.e., \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{soft}\\left(s_0,s_1,...,s_{C-1}\\right) \\approx \\text{max}\\left(s_0,s_1,...,s_{C-1}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The fact that the softmax approximates the maximum can be proved formally (see text).\n",
    "\n",
    "\n",
    "- Below we show the one dimensional comparison.  The softmax is shown in dashed black, and the max in green.\n",
    "\n",
    "\n",
    "  <img src= '../../mlrefined_images/superlearn_images/Fig_4_2.png' width=\"50%\" height=\"auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Replace the $p^{th}$ summand of our ReLU cost with its softmax approximation\n",
    "\n",
    "\\begin{equation}\n",
    "g_p\\left(\\mathbf{w}\\right) = \\text{soft}\\left(0,-\\overset{\\,}{y}_{p}\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,}\\right) = \\text{log}\\left(1 + e^{-\\overset{\\,}{y}_{p}\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,}}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- The overall cost function is then: $g\\left(\\mathbf{w}\\right)=\\sum_{p=1}^P g_p\\left(\\mathbf{w}\\right) = \\underset{p=1}{\\overset{P}{\\sum}}\\text{log}\\left(1 + e^{-\\overset{\\,}{y}_{p}\\mathring{\\mathbf{x}}_{p}^T\\mathbf{w}^{\\,}}\\right)$\n",
    "\n",
    "\n",
    "- This is the *Softmax cost* we saw previously derived from the logistic regression perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- This is why the cost is called *Softmax*, since it derives from the general softmax approximation to the max function.\n",
    "\n",
    "\n",
    "- Note that *like* the ReLU cost - as we already know - the Softmax cost is convex. \n",
    "\n",
    "\n",
    "- However *unlike* the ReLU cost, the softmax has infinitely many derivatives and Newton's method can therefore be used to minimize it. \n",
    "\n",
    "\n",
    "- Moreover, softmax does not have a trivial solution at zero like the ReLU cost does.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Nonetheless, the fact that the Softmax cost so closely approximates the ReLU shows just how closely aligned both logistic regression and the perceptron truly are. \n",
    "\n",
    "\n",
    "- Practically speaking their differences lie in how well - for a particular dataset - one can optimize either one, along with (what is very often slight) differences in the quality of each cost function's learned decision boundary.  \n",
    "\n",
    "\n",
    "- Of course when the Softmax is employed from the perceptron perspective there is no qualitative difference between the perceptron and logistic regression at all."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "139px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 9.5  Feature scaling via PCA sphering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In the [Section 9.3](https://jermwatt.github.io/machine_learning_refined/notes/9_Feature_engineer_select/9_3_Scaling.html) we saw how *feature scaling* via *standard normalization* significantly improves the topology of a machine learning cost function.\n",
    "\n",
    "\n",
    "- This enables much more rapid minimization via first order methods like e.g., the generic gradient descent algorithm.  \n",
    "\n",
    "\n",
    "- In this Section we describe how PCA is used to perform a more advanced form of standard normalization - commonly called *PCA sphereing* (also commonly referred to as *whitening*).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- With this improvement on standard normalization we use PCA to rotate the mean-centered dataset so that its largest orthogonal directions of variance allign with the coordinate axes prior to scaling each input by its standard deviation.  \n",
    "\n",
    "\n",
    "\n",
    "- This typically allows us to better compactify the data, resulting in a cost function whose contours are even more 'circular' than that provided by standard normalization and thus makes cost functions even easier to optimize.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can toggle the code on and off in this presentation via the button below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# custom libs\n",
    "from mlrefined_libraries import unsupervised_library as unsuplib\n",
    "from mlrefined_libraries import basics_library as baslib\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "\n",
    "unsup_datapath = '../../mlrefined_datasets/unsuperlearn_datasets/'\n",
    "sup_datapath = '../../mlrefined_datasets/superlearn_datasets/'\n",
    "\n",
    "normalizers = unsuplib.normalizers\n",
    "optimizers = optlib.optimizers\n",
    "cost_lib = superlearn.cost_functions\n",
    "classification_plotter = superlearn.classification_static_plotter.Visualizer();\n",
    "\n",
    "\n",
    "# this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  The PCA sphering scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Before discussing PCA-sphereing, let us recall a few key notations and ideas from our discussion of PCA itself (see Section 8.3).\n",
    "\n",
    "\n",
    "- Stacking our input data together column-wise we create our $N\\times P$ data matrix $\\mathbf{X}$.  \n",
    "\n",
    "\n",
    "\n",
    "- We then denote $\\frac{1}{P}\\mathbf{X}\\mathbf{X}^T + \\lambda \\mathbf{I}_{N\\times N}$ the regularized covariance matrix of this data \n",
    "\n",
    "\n",
    "- And $\\frac{1}{P}\\mathbf{X}^{\\,} \\mathbf{X}^T +\\lambda \\mathbf{I}_{N\\times N}= \\mathbf{V}^{\\,}\\mathbf{D}^{\\,}\\mathbf{V}^T$ its eigenvalue/vector decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Also recall that when performing PCA we first *mean-center* our dataset.\n",
    "\n",
    "\n",
    "- We then aim to represent each of our mean-centered datapoints \n",
    "datapoint $\\mathbf{x}_p$ by $\\mathbf{w}_p = \\mathbf{V}_{\\,}^T\\mathbf{x}_p^{\\,}$. \n",
    "\n",
    "\n",
    "- In the space spanned by the principal components we can represent the entire set of transformed mean-centered data as \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{(PCA transformed data)}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\mathbf{W} = \\mathbf{V}^T\\mathbf{X}^{\\,}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Remember that this PCA transformation *rotates* the mean-centered data so that its largest orthogonal directions of variance align with the coordinate axes of the input space.\n",
    "\n",
    "\n",
    "- \"PCA-sphereing\" takes this process one step further.\n",
    "\n",
    "\n",
    "- To *sphere* the data we simply divide off the standard deviation along each coordinate of the PCA-transformed (mean-centered) data $\\mathbf{W}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- PCA-sphereing is simply the standard normalization with a step inserted in between mean centering and the dividing off of standard deviations.\n",
    "\n",
    "\n",
    "- In between these two steps we rotate the data using PCA.  \n",
    "\n",
    "\n",
    "- By rotating the data prior to scaling we can typically shrink the space consumed by the data considerably more than standard normalization.\n",
    "\n",
    "\n",
    "- This simultaneously makes the associated cost function considerably more \"circular\" and much easier minimize properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In the Figure below we show a generic comparison of how standard normalization and PCA sphereing affect a prototypical dataset, and its associated cost function.  \n",
    "\n",
    "\n",
    "- Because PCA sphereing first rotates the data prior to scaling it typically results in more compact transformed data, and a transformed cost function with more 'circular' contours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  <img src= '../../mlrefined_images/unsupervised_images/standard_normal_vs_pca_sphereing.png' width=\"60%\"  height=\"auto\" alt=\"\"/>\n",
    "      <img src= '../../mlrefined_images/unsupervised_images/standard_vs_sphereing_contours.png' width=\"60%\"  height=\"auto\" alt=\"\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Formally if the *standard normalalization* scheme applied to a single datapoint $\\mathbf{x}_p$ can be written in two steps as... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "**Standard normalization scheme:**\n",
    "1.  **(mean center)** for each $n$ replace $x_{p,n} \\longleftarrow \\left({x_{p,n} - \\mu_n}\\right)$ where $\\mu_n = \\frac{1}{P}\\sum_{p=1}^{P}x_{p,n}$\n",
    "2.  **(divide off std)** for each $n$ replace $x_{p,n} \\longleftarrow \\frac{x_{p,n}}{\\sigma_n}$ where $\\sigma_n = \\sqrt{\\frac{1}{P}\\sum_{p=1}^{P}\\left(x_{p,n}\\right)^2}$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- ... then PCA-sphereing scheme can be then be written in three highly related steps as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "**PCA-sphereing scheme:**\n",
    "1.  **(mean center)** for each $n$ replace $x_{p,n} \\longleftarrow \\left({x_{p,n} - \\mu_n}\\right)$ where $\\mu_n = \\frac{1}{P}\\sum_{p=1}^{P}x_{p,n}$\n",
    "2.  **(PCA rotation)** transform $\\mathbf{w}_p = \\mathbf{V}_{\\,}^T\\mathbf{x}_p^{\\,}$ where $\\mathbf{V}$ is the full set of eignenvectors of the reguliarzed covariance matrix\n",
    "3.  **(divide off std)** for each $n$ replace $w_{p,n} \\longleftarrow \\frac{w_{p,n}}{\\sigma_n}$ where $\\sigma_n = \\sqrt{\\frac{1}{P}\\sum_{p=1}^{P}\\left(w_{p,n}\\right)^2}$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We can express step 3 of PCA-sphereing more efficiently using the *eigenvalues* of the regularized covariance matrix.  \n",
    "\n",
    "\n",
    "- The Raleigh quotient definition of the $n^{th}$ eigenvalue $d_n$ of this matrix states that numerically speaking \n",
    "\n",
    "\\begin{equation}\n",
    "d_n = \\frac{1}{P}\\mathbf{v}_n \\mathbf{X}_{\\,}^{\\,} \\mathbf{X}_{\\,}^T \\mathbf{v}_n \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- Here $\\mathbf{v}_n$ is the $n^{th}$ and corresponding eigenvector.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In terms of our PCA transformed data this is equivalently written as\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "d_n = \\frac{1}{P}\\left\\Vert \\mathbf{v}_n^T \\mathbf{X} \\right \\Vert_2^2 = {\\frac{1}{P}\\sum_{p=1}^{P}\\left(w_{p,n}\\right)^2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- In other words the $n^{th}$ eigenvalue is the *variance* along the $n^{th}$ axis of the PCA-transformed data.  \n",
    "\n",
    "\n",
    "- Since the final step of PCA-sphereing has us divide off the standard deviation along each axis of the transformed data we can then write it equivalently in terms of the eigenvalues as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "---\n",
    "**PCA-sphereing scheme:**\n",
    "1.  **(mean center)** for each $n$ replace $x_{p,n} \\longleftarrow \\left({x_{p,n} - \\mu_n}\\right)$ where $\\mu_n = \\frac{1}{P}\\sum_{p=1}^{P}x_{p,n}$\n",
    "2.  **(PCA rotation)** transform $\\mathbf{w}_p = \\mathbf{V}_{\\,}^T\\mathbf{x}_p^{\\,}$ where $\\mathbf{V}$ is the full set of eignenvectors of the reguliarzed covariance matrix\n",
    "3.  **(divide off std)**  for each $n$ replace $w_{p,n} \\longleftarrow \\frac{w_{p,n}}{d_n^{1/_2}}$ where $d_n^{1/_2}$ is the square root of the $n^{th}$ eigenvalue of the regularized covariance matrix\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- While expressing PCA-sphereing in may seem largely cosmetic, it is indeed computationally advantageous to simply use the eigenvalues in step 3 of the method...\n",
    "\n",
    "\n",
    "- ...instead of re-computing the standard deviations along each transformed input axis) since we compute them anyway in performing PCA in step 2."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "214px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

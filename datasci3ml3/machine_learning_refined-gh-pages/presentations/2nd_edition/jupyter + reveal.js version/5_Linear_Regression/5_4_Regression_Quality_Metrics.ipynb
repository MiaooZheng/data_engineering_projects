{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5.4  Regression Quality Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In this Section we describe simple metrics for judging the quality of a trained regression model.\n",
    "\n",
    "\n",
    "- We also look at how to make predictions using a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- You can toggle the code on and off in this presentation via the button below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "\n",
    "# demos for this notebook\n",
    "regress_plotter = superlearn.lin_regression_demos\n",
    "optimizers = optlib.optimizers\n",
    "static_plotter = optlib.static_plotter.Visualizer()\n",
    "datapath = '../../mlrefined_datasets/superlearn_datasets/'\n",
    "\n",
    "# import autograd functionality to bulid function's properly for optimizers\n",
    "import autograd.numpy as np\n",
    "\n",
    "# import timer\n",
    "from datetime import datetime \n",
    "\n",
    "# This is needed to compensate for %matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making predictions using a trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- If we denote the optimal set of weights found by minimizing a regression cost function by $\\mathbf{w}^{\\star}$ then note we can write our fully tuned linear model as \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{model}\\left(\\mathbf{x},\\mathbf{w}^{\\star}\\right) =  \\mathring{\\mathbf{x}}_{\\,}^T\\mathbf{w}^{\\star}   = w_0^{\\star} + x_{1}^{\\,}w_1^{\\star} + x_{2}^{\\,}w_2^{\\star} + \\cdots + x_{N}^{\\,}w_N^{\\star}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- Given an input (whether one from our training dataset or a new input) $\\mathbf{x}_{\\,}$ we predict its output $y_{\\,}$ by passing it along with our trained weigths into our model as \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{model}\\left(\\mathbf{x}_{\\,},\\mathbf{w}^{\\star}\\right)  = y_{\\,}\n",
    "\\end{equation}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  <img src= '../../mlrefined_images/superlearn_images/Fig_3_5_new.png' width=\"100%\" height=\"100%\" alt=\"\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Judging the quality of a trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Once we have successfully minimized the a cost function for linear regression it is an easy matter to determine the quality of our regression model.\n",
    "\n",
    "\n",
    "- We must simply evaluate a cost function using our optimal weights. \n",
    "\n",
    "\n",
    "- We can then evalaute the quality of this trained model using a Least Squares cost.\n",
    "\n",
    "\n",
    "- This is especially natural to use when we employ this cost in training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " \n",
    "- To do this we plug in our trained model and dataset into the Least Squares cost - giving the *Mean Squared Error* (or *MSE* for short) of our trained model\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE}=\\frac{1}{P}\\sum_{p=1}^{P}\\left(\\text{model}\\left(\\mathbf{x}_p,\\mathbf{w}^{\\star}\\right) -y_{p}^{\\,}\\right)^{2}.\n",
    "\\end{equation}\n",
    "\n",
    "- The name for this quality measurement describes precisely what the Least Squares cost computes - the average (or *mean*) squared error.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In the same way we can employ the Least Absolute Deviations cost to determine the quality of our trained model.  \n",
    "\n",
    "\n",
    "- Plugging in our trained model and dataset into this cost computes the Mean Absolute Deviations (or *MAD* for short).\n",
    "\n",
    "\n",
    "- This is precisely what this cost function computes\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MAD}=\\frac{1}{P}\\sum_{p=1}^{P}\\left\\vert\\text{model}\\left(\\mathbf{x}_p,\\mathbf{w}^{\\star}\\right) -y_{p}^{\\,}\\right\\vert.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- These two measurements differ in precisely the ways we have seen their respective cost functions differ - e.g., the MSE measure is far more sensitive to *outliers*.  \n",
    "\n",
    "\n",
    "- Which measure one employs in practice can therefore depend on personal and/or occupational preference, or the nature of a problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Of course in general the *lower* one can make a quality measures, by proper tuning of model weights, the *better* the quality of the corresponding trained model (and vice versa).  \n",
    "\n",
    "\n",
    "- However the threshold for what one considers 'good' or 'great'  performance can depend on personal preference, an occupational or institutionally set benchmark, or some other problem-dependent concern."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

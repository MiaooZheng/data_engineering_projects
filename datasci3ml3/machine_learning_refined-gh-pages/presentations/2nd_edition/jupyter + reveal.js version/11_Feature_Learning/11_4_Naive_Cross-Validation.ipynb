{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Chapter 11: Principles of Feature Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 11.4 Naive Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can toggle the code on and off in this presentation via the button below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- By carefully searching through a set of models ranging in complexity we can identify the best of the bunch, the one that provides minimal error on the validation set.\n",
    "\n",
    "- This comparison of models is called *cross-validation* (or sometimes *model search* or *selection*).\n",
    "\n",
    "- Cross-validation is the basis of feature learning as it provides a systematic way to *learn* (as opposed to *engineer*, as detailed in Chapter 10) the proper form a nonlinear model should take for a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In this Section we introduce what we refer to as *naive* cross-validation.  This consists of a search over a set of models of *varying capacity*, with each model fully optimized over the training set, in search of a validation error-minimizing choice.   While it is simple in principle and in implementation, naive cross-validation is generally speaking very expensive (computationally speaking) and often results in a rather *coarse* model search that can miss (or 'skip over') the ideal amount of complexity desired for a given dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import autograd.numpy as np\n",
    "from mlrefined_libraries import nonlinear_superlearn_library as nonlib\n",
    "datapath = '../../mlrefined_datasets/nonlinear_superlearn_datasets/'\n",
    "\n",
    "# plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# this is needed to compensate for %matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose we want to select one of the $M$ models below that has the ideal amount of complexity for a given dataset:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}\n",
    "\\\n",
    "\\text{model}_1\\left(\\mathbf{x},\\Theta_1\\right) = w_0 + f_1\\left(\\mathbf{x}\\right){w}_{1}   \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,   \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,    \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,    \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,    \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,      \\,\\,\\,  \\,\\,    \\\\\n",
    "\\text{model}_2\\left(\\mathbf{x},\\Theta_2\\right) = w_0 + f_1\\left(\\mathbf{x}\\right){w}_{1} +  f_2\\left(\\mathbf{x}\\right){w}_{2}   \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,   \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,    \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,    \\,\\,\\,   \\,\\,\\,  \\,\\,   \\\\\n",
    "\\,\\,\\,\\,\\,  \\,\\,\\,\\,\\, \\,\\,\\,\\,\\, \\,\\,\\,\\,\\,  \\,\\,\\,\\,\\,  \\,\\,\\,\\,\\,  \\,\\,\\,\\,\\,\\vdots  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,    \\,\\,\\,  \\,\\,\\,  \\,\\,\\,  \\,\\,\\,    \\\\\n",
    "\\text{model}_M\\left(\\mathbf{x},\\Theta_M\\right) = w_0 + f_1\\left(\\mathbf{x}\\right){w}_{1} +  f_2\\left(\\mathbf{x}\\right){w}_{2} + \\cdots + f_M\\left(\\mathbf{x}\\right)w_M.\n",
    "\\end{array}\n",
    "\\label{equation:naive-cross-validation-model-set}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Naive cross-validation entails taking the following steps:\n",
    "\n",
    "- split original data randomly into training and validation portions\n",
    "- optimize every model to completion\n",
    "- measure the error of all $M$ fully trained models on each portion of the data\n",
    "- pick the one that achieves *minimum validation*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p>\n",
    "  <img align=\"right\" src= '../../mlrefined_images/nonlinear_superlearn_images/Figure_11_28.png' width=\"60%\"  alt=\"\"/>\n",
    "</p>\n",
    "\n",
    "<b>(top panel)</b> A prototypical training and validation error plots resulting from a prototypical run of naive cross-validation. <br><br><b>(bottom panels)</b> We turn the capacity dial from left to right, searching over a range of models of increasing capacity in search of a validation error minimizing model, while keeping the optimization dial set all the way to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the top panel of [Figure 11.28](#11.28) we show the generic sort of training (in blue) and validation (in yellow) errors we find in practice as a result of following this naive cross-validation scheme. The horizontal axis of this plot shows (roughly speaking) the complexity of each of our $M$ *fully optimized* models, with the output on the vertical axis denoting error level.  As can be seen in the Figure, our low complexity models *underfit* the data as reflected in their high training and validation errors. As the model complexity increases further, fully optimized models achieve lower training error since increasing model complexity allows us to constantly improve how well we can represent training data. This fact is reflected in the monotonically decreasing nature of the (blue) training error curve. On the other hand, while the validation error of our models will tend to decrease at first as we increase complexity, this trend continues only up to a point where *overfitting* of the training data begins. Once we reach a model complexity that overfits the training data our validation error starts to increase again, as our model becomes less and less a fair representation of \"data we might receive in the future\" generated by the same phenomenon.  \n",
    "\n",
    "Note in practice that while training error typically follows the monotonically decreasing trend shown in the top panel of Figure 11.28, validation error can oscillate up and down more than once depending on the models tested.  In any event, we determine the best fully optimized model from the set by choosing the one that *minimizes* validation error.  This is often referred to as solving the *bias-variance trade-off*, as it involves determining a model that (ideally) neither underfits (or has high bias) nor overfits (or has high variance). \n",
    "\n",
    "In the bottom row of [Figure 11.28](#figure-11-28) we summarize this naive approach to cross-validation using the capacity / optimization dial conceptualization first introduced in Section 11.3.2.  Here we set our *optimization* dial all the way to the right - indicating that we optimize every model to completion - and in ranging over our set of $M$ models we turn the *capacity* dial from left to right starting with $m=1$ (on the left) and ending with $m=M$ (all the way to the right - with the value of $m$ increasing by $1$ at each notch of the dial).  Since in this case the *capacity* dial roughly governs model complexity - as summarized visually in the bottom row of Figure 11.24 -  our model search reduces to setting this dial correctly to the minimum validation error setting.  To visually denote how this is done we wrap the prototypical validation error curve shown in the top panel of [Figure 11.28](#figure-11-28) clockwise around the capacity dial.  We can then imagine setting this dial correctly (and automatically) to the value of $m$ providing minimum validation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example.</span>  Naive cross-validation and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In the animation that follows we use naive cross-validation on a toy regression dataset by employing a small set of polynomial models having degrees $1 \\leq m \\leq 8$.\n",
    "\n",
    "- These models are naturally ordered from low to high capacity, as we increase the degree $m$ of the polynomial.\n",
    "\n",
    "- Here we use $\\frac{2}{3}$ of the data points for training (blue), and the other $\\frac{1}{3}$ for validation (yellow).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"1000\" height=\"500\" controls loop>\n",
       "  <source src=\"videos/animation_6.mp4\" type=\"video/mp4\">\n",
       "  </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# run demonstration\n",
    "demo3 = nonlib.regression_basis_single.Visualizer()\n",
    "csvname = datapath + 'noisy_sin_sample.csv'\n",
    "demo3.load_data(csvname)\n",
    "demo3.brows_single_cross_val(savepath='videos/animation_6.mp4',basis='poly',num_elements = [v for v in range(1,9)],folds = 3,fps=1)\n",
    "\n",
    "# load in video and display\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"1000\" height=\"500\" controls loop>\n",
    "  <source src=\"videos/animation_6.mp4\" type=\"video/mp4\">\n",
    "  </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example.</span>   Naive cross-validation and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In the animation that follows we use naive cross-validation on a toy classification dataset by employing a small set of polynomial models having degrees $1 \\leq m \\leq 7$.\n",
    "\n",
    "- These models are naturally ordered from low to high capacity, as we increase the degree $m$ of the polynomial.\n",
    "\n",
    "- Here we use (approximately) $\\frac{4}{5}$ of the data points for training (blue), and the other $\\frac{1}{5}$ for validation (yellow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"1000\" height=\"500\" controls loop>\n",
       "  <source src=\"videos/animation_7.mp4\" type=\"video/mp4\">\n",
       "  </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# load in dataset\n",
    "csvname = datapath + 'new_circle_data.csv'\n",
    "data = np.loadtxt(csvname,delimiter = ',')\n",
    "x = data[:-1,:]\n",
    "y = data[-1:,:] \n",
    "\n",
    "### run cross validation experiments ###\n",
    "degrees = np.arange(1,8)\n",
    "models_1 = []\n",
    "for j in degrees:\n",
    "    # import the v1 library\n",
    "    mylib1 = nonlib.intro_general_library.superlearn_setup.Setup(x,y)\n",
    "\n",
    "    # choose features\n",
    "    mylib1.choose_features(name = 'polys',degree = j)\n",
    "    \n",
    "    # choose normalizer\n",
    "    mylib1.choose_normalizer(name = 'none')\n",
    "\n",
    "    # split into training and testing sets\n",
    "    mylib1.make_train_valid_split(train_portion = 0.66)\n",
    "\n",
    "    # choose cost\n",
    "    mylib1.choose_cost(name = 'softmax')\n",
    "\n",
    "    # fit an optimization\n",
    "    mylib1.fit(optimizer = 'newtons_method',max_its = 5,epsilon = 10**(-8))\n",
    "\n",
    "    # add model to list\n",
    "    models_1.append(mylib1)\n",
    "\n",
    "# load up animator\n",
    "csvname = datapath + 'new_circle_data.csv'\n",
    "demo2 = nonlib.crossval_classification_animator.Visualizer(csvname)\n",
    "\n",
    "# animate based on the sample weight history\n",
    "savepath = 'videos/animation_7.mp4'\n",
    "demo2.animate_crossval_classifications(savepath,models_1,fps=1)\n",
    "\n",
    "# load in video and display\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"1000\" height=\"500\" controls loop>\n",
    "  <source src=\"videos/animation_7.mp4\" type=\"video/mp4\">\n",
    "  </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problems with naive cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Since the process generally involves trying out a range of models where each model is *optimized completely*, naive cross-validation can be very expensive computationally speaking. \n",
    "\n",
    "- The *capacity* difference between even adjacent models (e.g., those consisting of $m$ and $m+1$ units) can be quite large. Since each model is fully optimized this can lead to huge jumps in the range of model complexities tried out on a dataset, leading to a *coarse* resolution model search that can 'miss out' on an ideal amount of nonlinearity for a given dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<a id='figure-11-31'></a>\n",
    "<figure>\n",
    "<p>\n",
    "  <img src= '../../mlrefined_images/nonlinear_superlearn_images/Figure_11_31.png' width=\"95%\"  alt=\"\"/>\n",
    "</p>\n",
    "<figcaption> <strong>Figure: 11.31 </strong> <em> \n",
    "Naive cross-validation depicted as the proper adjustment of the capacity dial.  While ideally we would like the resolution of our search to be fine-grained (as depicted in the left panel) often times it results - due to the very nature of the approach -  in a rather coarse search for validation error minimizing models (as depicted in the right panel - where large turns of the capacity dial easily skip over the validation error minimizing choice).\n",
    "</em>\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "116.992px",
    "width": "251.992px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "736.493px",
    "left": "0px",
    "right": "1388px",
    "top": "113.229px",
    "width": "211.997px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
